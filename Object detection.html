<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice-Enabled Accessibility Assistant</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tesseract.js/4.1.1/tesseract.min.js"></script>
    <style>
        /* Previous styles remain the same */
        body {
            margin: 0;
            padding: 20px;
            font-family: Arial, sans-serif;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
            color: #541cf0;

        }
        .container .button{
            color: #a4e1f1;
        }
        #videoContainer {
            position: relative;
            margin: 20px auto;
            max-width: 640px;
        }
        #video {
            width: 100%;
            max-width: 640px;
            border: 2px solid #333;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            max-width: 640px;
        }
        button {
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
            cursor: pointer;
        }
        #status, #results {
            margin: 10px;
            padding: 10px;
            border: 1px solid hsla(210, 87%, 84%, 0.914);
            border-radius: 5px;
        }
        .error {
            color: red;
            font-weight: bold;
        }
        #commandsList {
            text-align: left;
            margin: 20px;
            padding: 10px;
            background: white;
            border-radius: 5px;
        }
        #commandsList li{
            color: #333;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voice-Enabled Accessibility Assistant</h1>
        <div id="status">Loading...</div>

        <div class="button">
            <button id="startButton" onclick="startAssistant()" disabled>Start Assistant</button>
            <button id="stopButton" onclick="stopAssistant()" disabled>Stop Assistant</button>
        </div>
        <div id="commandsList">
            <h3>Voice Commands:</h3>
            <ul>
                <li>"Start" - Start the assistant</li>
                <li>"Stop" - Stop the assistant</li>
                <li>"What do you see" - Describe detected objects</li>
                <li>"Read text" - Read any detected text</li>
                <li>"Help" - List available commands</li>
            </ul>
        </div>
        <div id="videoContainer">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
        </div>
        <div id="results">No detections yet</div>
    </div>

    <script>
        // Global variables
        let model = null;
        let isRunning = false;
        let video = document.getElementById('video');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');
        let status = document.getElementById('status');
        let results = document.getElementById('results');
        let startButton = document.getElementById('startButton');
        let stopButton = document.getElementById('stopButton');
        let recognition = null;
        let synth = window.speechSynthesis;
        let lastSpokenTime = 0;
        const SPEAK_COOLDOWN = 2000; // 2 seconds between speeches
        let isProcessingCommand = false;

        // Initialize speech recognition
        function initSpeechRecognition() {
            if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
                recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                recognition.continuous = true;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    console.log('Speech recognition started');
                    status.textContent = 'Listening for commands...';
                };

                recognition.onresult = handleVoiceCommand;
                
                recognition.onend = () => {
                    console.log('Speech recognition ended');
                    if (isRunning) {
                        recognition.start();
                    }
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    speak('Speech recognition error. Please try again.');
                    if (isRunning) {
                        setTimeout(() => recognition.start(), 1000);
                    }
                };
            } else {
                speak('Speech recognition is not supported in this browser.');
            }
        }

        // Enhanced voice command handler
        async function handleVoiceCommand(event) {
            if (isProcessingCommand) return;
            
            isProcessingCommand = true;
            const command = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
            console.log('Voice command received:', command);

            try {
                if (command.includes('start')) {
                    if (!isRunning) {
                        await startAssistant();
                    } else {
                        speak('Assistant is already running');
                    }
                } else if (command.includes('stop')) {
                    if (isRunning) {
                        stopAssistant();
                    } else {
                        speak('Assistant is already stopped');
                    }
                } else if (command.includes('what do you see')) {
                    if (isRunning) {
                        await describeScene();
                    } else {
                        speak('Please start the assistant first');
                    }
                } else if (command.includes('read text')) {
                    if (isRunning) {
                        await performOCR();
                    } else {
                        speak('Please start the assistant first');
                    }
                } else if (command.includes('help')) {
                    listCommands();
                } else {
                    speak("Command not recognized. Say 'Help' for available commands.");
                }
            } catch (error) {
                console.error('Error processing command:', error);
                speak('Error processing command. Please try again.');
            } finally {
                isProcessingCommand = false;
            }
        }

        // Enhanced text-to-speech function
        function speak(text) {
            const now = Date.now();
            if (now - lastSpokenTime >= SPEAK_COOLDOWN) {
                // Cancel any ongoing speech
                synth.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                
                utterance.onend = () => {
                    console.log('Speech finished');
                    lastSpokenTime = Date.now();
                };

                utterance.onerror = (event) => {
                    console.error('Speech synthesis error:', event);
                };

                synth.speak(utterance);
                console.log('Speaking:', text);
            }
        }

        // List available commands
        function listCommands() {
            const commands = [
                'Available commands:',
                'Say "Start" to begin detection',
                'Say "Stop" to end detection',
                'Say "What do you see" for object detection',
                'Say "Read text" for text recognition',
                'Say "Help" to hear these commands again'
            ].join('. ');
            speak(commands);
        }

        // Initialize the application
        async function init() {
            try {
                status.textContent = 'Loading TensorFlow model...';
                speak('Loading assistant. Please wait.');
                
                // Load COCO-SSD model
                model = await cocoSsd.load();
                
                // Initialize speech recognition
                initSpeechRecognition();
                
                status.textContent = 'Assistant ready. Say "Start" or press the Start button.';
                startButton.disabled = false;
                speak('Assistant ready. Say "Help" for available commands.');
                
            } catch (error) {
                status.innerHTML = `<span class="error">Error initializing: ${error.message}</span>`;
                speak('Error initializing assistant. Please refresh the page.');
                console.error('Initialization error:', error);
            }
        }

        // Enhanced start assistant function
        async function startAssistant() {
            try {
                if (!model) {
                    throw new Error('Model not loaded yet. Please wait.');
                }

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });

                video.srcObject = stream;
                await new Promise(resolve => video.onloadedmetadata = resolve);
                
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                isRunning = true;
                startButton.disabled = true;
                stopButton.disabled = false;
                status.textContent = 'Assistant is running';
                speak('Assistant started. Say "What do you see" to detect objects.');

                if (recognition) {
                    try {
                        await recognition.start();
                    } catch (e) {
                        if (e.name === 'NotAllowedError') {
                            speak('Please allow microphone access to use voice commands.');
                        }
                    }
                }

                detectFrame();

            } catch (error) {
                status.innerHTML = `<span class="error">Error starting assistant: ${error.message}</span>`;
                speak('Error starting assistant. Please check camera permissions.');
                console.error('Start error:', error);
            }
        }

        // Enhanced stop assistant function
        function stopAssistant() {
            isRunning = false;
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            if (recognition) {
                recognition.stop();
            }
            startButton.disabled = false;
            stopButton.disabled = true;
            status.textContent = 'Assistant stopped';
            results.textContent = 'No detections';
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            speak('Assistant stopped. Say "Start" to begin again.');
        }

        // Enhanced scene description
        async function describeScene() {
            if (!isRunning) {
                speak('Assistant is not running. Say "Start" to begin.');
                return;
            }
            await performDetection(true); // true flag to force speaking results
        }

        // Main detection loop
        async function detectFrame() {
            if (!isRunning) return;
            await performDetection(false);
            requestAnimationFrame(detectFrame);
        }

        // Enhanced object detection
        async function performDetection(speakResults) {
            try {
                const predictions = await model.detect(video);
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                let detectedObjects = new Set(); // Use Set to avoid duplicates
                
                predictions.forEach(prediction => {
                    if (prediction.score > 0.66) {
                        // Draw bounding box
                        ctx.strokeStyle = '#00ff00';
                        ctx.lineWidth = 4;
                        ctx.strokeRect(...prediction.bbox);
                        
                        // Draw label
                        ctx.fillStyle = '#00ff00';
                        ctx.font = '16px Arial';
                        ctx.fillText(
                            `${prediction.class} ${(prediction.score * 100).toFixed(0)}%`,
                            prediction.bbox[0],
                            prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
                        );

                        detectedObjects.add(prediction.class);
                    }
                });

                const objectsArray = Array.from(detectedObjects);
                if (objectsArray.length > 0) {
                    const text = `I see: ${objectsArray.join(', ')}`;
                    results.textContent = text;
                    if (speakResults) {
                        speak(text);
                    }
                } else if (speakResults) {
                    speak('No objects detected');
                }

            } catch (error) {
                console.error('Detection error:', error);
                if (speakResults) {
                    speak('Error during detection. Please try again.');
                }
            }
        }

        // Enhanced OCR function
        async function performOCR() {
            try {
                speak('Scanning for text...');
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                const result = await Tesseract.recognize(canvas, 'eng', {
                    logger: m => console.log(m)
                });

                const text = result.data.text.trim();
                if (text) {
                    speak('Found text: ' + text);
                    results.textContent = 'Text: ' + text;
                } else {
                    speak('No text detected');
                }
            } catch (error) {
                console.error('OCR error:', error);
                speak('Error reading text. Please try again.');
            }
        }

        // Initialize on page load
        window.onload = init;
    </script>
</body>
</html>